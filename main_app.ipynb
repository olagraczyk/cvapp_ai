{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a348d08-ae51-4cfe-a3b3-e8ae1177dbe0",
   "metadata": {},
   "source": [
    "## Connecting to Docks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24c971a1-0368-4593-a982-c869a55a56cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client -q\n",
    "%pip install python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "966bccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4fc70-b203-42ad-91e6-4e427812e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# I only want read access\n",
    "SCOPES = ['https://www.googleapis.com/auth/documents.readonly']\n",
    "\n",
    "# Paths to token and credits\n",
    "#Client secret json is downloaded from my Google Cloud Console\n",
    "CREDS_PATH = 'auth/client_secret.json'\n",
    "# Token json will be auto-created after you authorize your app the first time\n",
    "TOKEN_PATH = 'auth/token.json'\n",
    "\n",
    "def get_credentials():\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_PATH):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_PATH, SCOPES)\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(CREDS_PATH, SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_PATH, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "def read_google_doc(doc_id):\n",
    "    creds = get_credentials() #Makes sure I am authenticated\n",
    "    service = build('docs', 'v1', credentials=creds) #This connects to Docs API\n",
    "    doc = service.documents().get(documentId=doc_id).execute() #Get the content\n",
    "    \n",
    "    content = \"\"\n",
    "    for element in doc.get(\"body\").get(\"content\"):\n",
    "        if \"paragraph\" in element:\n",
    "            for text_run in element[\"paragraph\"].get(\"elements\", []):\n",
    "                if \"textRun\" in text_run:\n",
    "                    content += text_run[\"textRun\"][\"content\"]\n",
    "    return content\n",
    "\n",
    "#Loads the environment variables, where I have saved the Doc Id\n",
    "load_dotenv()\n",
    "doc_id = os.getenv(\"GOOGLE_DOC_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471863c-5bf2-4900-afc4-fe9bcf34ab15",
   "metadata": {},
   "source": [
    "App will read the document every time I run it. \n",
    "\n",
    "Content could be cached and stored in a file, but with 8 pages it only took about 4 seconds, and adds additional value, that content is up to date, even if i make changes between uses of the app. Example on how to save the cached text locally is down below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccf051-14c4-4d93-aa50-82a3be260107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linkedin: https://www.linkedin.com/in/ola-graczyk/\n",
      " \n",
      "1.      Work experience\n",
      "1.1   UX/UI Designer\n",
      "Time: October 2024  - November 2024 ( 2 months )\n",
      "Company: DynamicoAI (Now Firemind)\n",
      "About the company: DynamicoAI owned a product called Enhanced IQ. It is an enterprise-grade platform that makes it simple to scale generative AI across the organisation. The platform can be integrated with the most popular databases and systems and sensitive data is protected. It can be used by employees on all levels for example to search company sharepoint,  retrieve data, write structured prompts to make working faster.\n",
      "About my role:\n",
      "As part of my role at DynamicoAI, I was responsible for evaluating the Enhanced IQ platform with a fresh perspective, identifying potential issues, and suggesting improvements. My key responsibilities included:\n",
      "-        Conducted a thorough review of the platform, documenting all observations, usability concerns, and bugs.\n",
      "-        Compiled findings into a structured report\n"
     ]
    }
   ],
   "source": [
    "experience_text = read_google_doc(doc_id)\n",
    "\n",
    "#print some of the content to show that this is working\n",
    "print(experience_text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786e6a2b-0bd0-4763-ba84-370d71daabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save locally\n",
    "with open('cached_experience.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(experience_text)\n",
    "\n",
    "# Later, you can read from file without hitting Google API\n",
    "# with open('cached_experience.txt', 'r', encoding='utf-8') as f:\n",
    "#     experience_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daad460-64a9-4b70-9b7a-a9fb90f7b98e",
   "metadata": {},
   "source": [
    "## Scrape the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c7bcde-6f29-48a7-b338-8bec215ead53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 -q\n",
    "from web_scraper import scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4063f7e3-aebc-4c19-b1d4-981ce9f0dc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste the link to job description:  https://justjoin.it/job-offer/allegro-junior-machine-learning-engineer---e-xperience-associate-warszawa-ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "AI/ML\n",
      "Junior Machine Learning Engineer - e-Xperience Associate\n",
      "Allegro\n",
      "Warszawa\n",
      "Type of work\n",
      "Full-time\n",
      "Experience\n",
      "Junior\n",
      "Employment Type\n",
      "Permanent\n",
      "Operating mode\n",
      "Hybrid\n",
      "Allegro\n",
      "At Allegro, we build and maintain some of the most distributed and scalable applications in Central Europe. Work with us \n"
     ]
    }
   ],
   "source": [
    "url = input(\"Paste the link to job description: \")\n",
    "\n",
    "scrape(url)\n",
    "\n",
    "with open('job_description.txt', 'r', encoding='utf-8') as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "print(job_description[300:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0b3de",
   "metadata": {},
   "source": [
    "## LLMs + Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4f937",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4de609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2350cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.24 requires langchain-text-splitters<1.0.0,>=0.3.8, which is not installed.\n",
      "langchain 0.3.24 requires langchain-core<1.0.0,>=0.3.55, but you have langchain-core 0.1.23 which is incompatible.\n",
      "langchain 0.3.24 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.0.87 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain-core==0.1.23\n",
    "%pip install --quiet langchain==0.1.1\n",
    "%pip install --quiet langchain-google-genai==0.0.6\n",
    "%pip install --quiet -U langchain-community==0.0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "# from langchain.schema.prompt_template import format_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f9ba29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olagr\\Desktop\\Programming\\CVApp\\cvapp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4fecf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Title of a job:** Junior Machine Learning Engineer - e-Xperience Associate\n",
      "\n",
      "2. **Role Summary Sentences:** This junior-level role focuses on deploying and maintaining machine learning models/algorithms within Allegro Ads.  The engineer will design, develop, and optimize ML pipelines, collaborating with data scientists and software engineers throughout the model lifecycle.  Responsibilities also include model management, monitoring, and tuning in a production environment.\n",
      "\n",
      "3. **Seniority Level and Years of Experience:** Junior level. The posting explicitly mentions \"Junior\" and is structured as an associate program (e-Xperience 2025) suggesting it's an entry-level position or intended for recent graduates with limited practical experience.  While specific years of experience aren't stated, proficiency in Python, SQL, and a passion for ML applications are key requirements.\n",
      "\n",
      "4. **Tech stack:** Python, SQL, GCP (Big Query, Composer, Vertex AI, Dataproc, Looker Studio), PySpark, Pandas, PyTorch/TensorFlow.\n",
      "\n",
      "5. **Top Soft Skills / Attributes:** Passionate about practical ML applications, decent analytical skills, curious and eager to learn, not afraid to challenge the status quo, good communication skills (English B2+).\n",
      "\n",
      "6. **Nice-to-Have Skills or Preferences:**  None explicitly stated, but prior experience with MLOps practices would likely be beneficial.\n",
      "\n",
      "7. **ATS Optimization Keywords:** Junior Machine Learning Engineer, e-Xperience Associate,  Machine Learning, ML, MLOps, Python, SQL, GCP, Big Query, Composer, Vertex AI, Dataproc, Looker Studio, PySpark, Pandas, PyTorch, TensorFlow,  Data Scientist, Software Engineer, Model Lifecycle, Model Management,  Monitoring, Tuning, Allegro, E-commerce.\n",
      "\n",
      "8. **Education Requirements:** Not explicitly mentioned, but a degree in a related field (Computer Science, Data Science, etc.) is likely implied for a Machine Learning Engineer role.\n",
      "\n",
      "9. **Location / Remote Work:** Hybrid model in Warsaw, Poland.  The internship portion emphasizes on-site presence, but a hybrid model is offered for the permanent position.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"job_prompt_template.txt\", \"r\") as file:\n",
    "   job_prompt_template = file.read()\n",
    "\n",
    "job_prompt = PromptTemplate.from_template(job_prompt_template)\n",
    "\n",
    "with open(\"job_description.txt\", \"r\") as file:\n",
    "    job_description = file.read()\n",
    "\n",
    "stuff_chain = (\n",
    "    {\"text\": lambda _: job_description}\n",
    "    | job_prompt         # Prompt for Gemini\n",
    "    | llm                # Gemini API function\n",
    "    | StrOutputParser()  # output parser\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "job_description_result = stuff_chain.invoke({})\n",
    "\n",
    "# Print the result\n",
    "print(job_description_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"job_prompt_template.txt\", \"r\") as file:\n",
    "   job_prompt_template = file.read()\n",
    "\n",
    "job_prompt = PromptTemplate.from_template(job_prompt_template)\n",
    "\n",
    "with open(\"job_description.txt\", \"r\") as file:\n",
    "    job_description = file.read()\n",
    "\n",
    "offer_chain = (\n",
    "    {\"text\": lambda _: job_description}\n",
    "    | job_prompt         # Prompt for Gemini\n",
    "    | llm                # Gemini API function\n",
    "    | StrOutputParser()  # output parser\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "job_description_result = offer_chain.invoke({})\n",
    "\n",
    "print(job_description_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e0db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2. Machine Learning Engineer with Python\n",
      "Time: October 2023  - September 2024\n",
      "Company: Fourteen33\n",
      "About the company: Fourteen33 provides AI/ML, cloud and marketplace services. Partners with Google\n",
      "About my role: Machine Learning Engineer with Python\n",
      "-        Contributed to the Gemini Cookbook by creating eight comprehensive notebooks and two Gemini-powered Streamlit applications showcasing various Gemini API functionalities. This involved researching, developing, testing, and enhancing each notebook to ensure accuracy and usability.\n",
      "-        Tested and improved all notebooks and applications submitted to the Gemini Cookbook by the team, ensuring their quality and consistency. This dedication to quality enabled the team to maintain high standards and deliver reliable, valuable resources for Gemini users.\n",
      "-        Developed an internal application for document search using Vertex AI, enhancing team efficiency and productivity by enabling fast and accurate document retrieval.\n",
      "- Notebooks with the use of Gemini that I have developed: Book Translation, Entity Extraction, RAG evaluation with LlamaIndex, Tagging and captioning images, Working with Charts, Graps and Slidedecks, Analyze the video Classification, Wolfram Alpha LLM API integration with Gemini\n",
      "\n",
      "\n",
      "2.1. SGH Warsaw School of Economics\n",
      "2.1.2.      Courses Taken\n",
      "-        Python Programming\n",
      "-        Big Data Programming in Databricks\n",
      "-        Cloud Computing in AWS\n",
      "-        Data Mining (Python and SAS)\n",
      "\n",
      "\n",
      "\n",
      "2.2.    Adam Mickiewicz University in PoznaĹ„ (Poland)\n",
      "2.2.2.      Courses Taken\n",
      "-            Python Programming\n",
      "-            Data Analysis and Visualization\n",
      "-            Artificial Intelligence and Artificial Life (programming)\n",
      "-            Artificial Intelligence Methods (programming)\n",
      "\n",
      "\n",
      "4.1.  Hackathon Winner at WPiK UAM (2023)\n",
      "Github code of the project: https://github.com/tykfikk/daj-DUHA/blob/main/DUHA8\n",
      "- Led a team of four students to develop a Python-based application using OpenAI API, earning first place in a Hackathon.\n",
      "- Developed an application that leverages my cognitive science knowledge on the cognitive limitations of individuals under the influence of intoxicating substances.  Depending on the situation, it offers guidance on calming techniques, such as meditation, or, in severe cases, prompts calling emergency services.\n",
      "\n",
      "\n",
      "5.      Projects\n",
      "5.1. Markov-Chain-Text-Generation-BLEU-Evaluation (Python and Databricks)\n",
      "https://github.com/olagraczyk/Markov-Chain-Text-Generation-BLEU-Evaluation\n",
      "5.2. Coffee-Point-Data-Analysis-Automation-in-Python (Python)\n",
      "https://github.com/olagraczyk/Coffee-Point-Data-Analysis-Automation-in-Python\n",
      "5.5. Hackathon Winning App Prototype (OpenAI API and Python)\n",
      "https://github.com/tykfikk/daj-DUHA/tree/main\n",
      "5.7. Data Mining Student Dropout\n",
      "Creation and evaluation of two machine learning models, Logistic Regression and Neural Network, to predict student dropout.\n",
      "https://github.com/olagraczyk/Data-Mining-Student-Dropout\n",
      "\n",
      "7.      Languages\n",
      "-        English at C1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with open(\"exp_prompt_template.txt\", \"r\") as file:\n",
    "#    exp_prompt_template = file.read()\n",
    "\n",
    "# exp_prompt = PromptTemplate.from_template(exp_prompt_template)\n",
    "\n",
    "# with open(\"cached_experience.txt\", \"r\") as file:\n",
    "#     full_experience = file.read()\n",
    "\n",
    "# exp_chain = (\n",
    "#     {\"experience\": lambda _: full_experience, \"job_offer\": lambda _: job_description_result}\n",
    "#     | exp_prompt         # Prompt for Gemini\n",
    "#     | llm                # Gemini API function\n",
    "#     | StrOutputParser()  \n",
    "# )\n",
    "\n",
    "# short_experience = exp_chain.invoke({})\n",
    "\n",
    "# print(short_experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d075986",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv_prompt_template.txt\", \"r\") as file:\n",
    "   cv_prompt_template = file.read()\n",
    "\n",
    "cv_prompt = PromptTemplate.from_template(cv_prompt_template)\n",
    "\n",
    "with open(\"cached_experience.txt\", \"r\") as file:\n",
    "    full_experience = file.read()\n",
    "\n",
    "cv_chain = (\n",
    "    {\"experience\": lambda _: full_experience, \"job_description\": lambda _: job_description_result}\n",
    "    | cv_prompt         \n",
    "    | llm                \n",
    "    | StrOutputParser()  \n",
    ")\n",
    "\n",
    "cv = cv_chain.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1082e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CV text as a markdown file\n",
    "with open(\"generated_cv.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601dc112",
   "metadata": {},
   "source": [
    "# Ola Graczyk\n",
    "(123) 456-7890 | ola.graczyk@email.com | linkedin.com/in/ola-graczyk | Warsaw, Poland\n",
    "\n",
    "## Professional Summary\n",
    "\n",
    "A highly motivated and curious Junior Machine Learning Engineer with a passion for practical ML applications and a proven ability to develop and implement ML solutions.  Proficient in Python, SQL, and eager to contribute to the e-Xperience Associate program at Allegro Ads.  Experienced in developing Gemini-powered Streamlit applications and conducting research on Named Entity Recognition (NER) using Vertex AI.  Seeking to leverage my analytical skills and strong learning aptitude to contribute to the model lifecycle, from development to deployment and ongoing optimization.\n",
    "\n",
    "## Experience\n",
    "\n",
    "**Fourteen33, Machine Learning Engineer with Python** | October 2023 - September 2024\n",
    "\n",
    "* Contributed to the Gemini Cookbook by developing eight notebooks and two Gemini-powered Streamlit applications, demonstrating proficiency in Python and practical ML application development.\n",
    "* Enhanced the quality and consistency of the Gemini Cookbook by testing and improving all submitted notebooks and applications.\n",
    "* Demonstrated a strong understanding of Gemini's capabilities by brainstorming and presenting ten innovative application ideas.\n",
    "* Led research and development for a client project focusing on Named Entity Recognition (NER), showcasing analytical skills and a proactive approach to problem-solving.\n",
    "* Developed an internal application for document search using Vertex AI, improving team efficiency and demonstrating experience with GCP services.\n",
    "* Completed the Machine Learning Engineer Certification, confirming a solid foundation in ML principles.\n",
    "\n",
    "**DynamicoAI (Now Firemind), UX/UI Designer** | October 2024 - November 2024\n",
    "\n",
    "* Conducted a comprehensive review of the Enhanced IQ platform, identifying usability issues and bugs, and documenting findings to improve platform performance and user experience.\n",
    "* Designed UI modifications using Figma, proposing improvements to button layouts and page structures.\n",
    "* Reviewed and simplified complex prompts for LLMs, leveraging knowledge of best practices in prompt engineering.\n",
    "* Created comprehensive documentation detailing findings and proposed changes, demonstrating strong communication skills.\n",
    "\n",
    "## Education\n",
    "\n",
    "**SGH Warsaw School of Economics, Master of Science, Advanced Analytics - Big Data** | September 2024 - Present\n",
    "\n",
    "* Relevant coursework: Python Programming, Big Data Programming in Databricks, Cloud Computing in AWS, Data Mining (Python and SAS), Databases in Oracle APEX, Real-time Analysis with Kafka.\n",
    "\n",
    "**Adam Mickiewicz University in Poznań, Bachelor of Science, Cognitive Science** | September 2021 - July 2024\n",
    "\n",
    "* Conducted research and an experiment with 40 participants for a bachelor's thesis on the interplay between human cognition and AI.\n",
    "* Relevant coursework:  Methodology and Statistics, Algorithmics, Python Programming, Data Analysis and Visualization, Artificial Intelligence and Artificial Life (programming), Artificial Intelligence Methods (programming).\n",
    "\n",
    "## Projects\n",
    "\n",
    "**Hackathon Winner at WPiK UAM (2023)** | [GitHub Repository](https://github.com/tykfikk/daj-DUHA/blob/main/DUHA8)\n",
    "\n",
    "* Led a team of four to develop a first-place, Python-based application using the OpenAI API during a 20-hour hackathon.\n",
    "* Leveraged cognitive science knowledge to design an application that assesses a user's condition and provides appropriate assistance.\n",
    "* Managed team responsibilities, including task delegation and technical support.\n",
    "\n",
    "**Markov Chain Text Generation - BLEU Evaluation (Python and Databricks)** | [GitHub Repository](https://github.com/olagraczyk/Markov-Chain-Text-Generation-BLEU-Evaluation)\n",
    "\n",
    "\n",
    "## Skills\n",
    "\n",
    "Python, SQL, GCP (Vertex AI), PySpark, Pandas, PyTorch/TensorFlow (currently learning),  Figma,  Streamlit,  Prompt Engineering,  Data Analysis,  Machine Learning,  MLOps (learning), Communication (English C1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8b727",
   "metadata": {},
   "source": [
    "# Remember to check the actual output in CV markdown since models can write incorrect information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce02b7d-8810-4b42-bd76-314c8e62c000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
